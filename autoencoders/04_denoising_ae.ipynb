{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general purpose python\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import importlib\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# general purpose data science\n",
    "import IPython\n",
    "import ipywidgets as ipw\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs\n",
    "import pylab\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "import statsmodels as sm\n",
    "\n",
    "# computer vision\n",
    "import cv2\n",
    "import imageio\n",
    "import PIL\n",
    "from PIL import *\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('pytorch device:    ', device.type)\n",
    "\n",
    "# geospatial\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "\n",
    "ignore_warnings = True\n",
    "if ignore_warnings:\n",
    "    warnings.filterwarnings('ignore')\n",
    "print('ignore warnings:   ', ignore_warnings)\n",
    "\n",
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "print('random seed:       ', seed)\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 400\n",
    "\n",
    "IPython.core.display.display(IPython.core.display.HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.options.display.max_colwidth = 32\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "pd.options.display.expand_frame_repr = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(sns.color_palette('muted'))\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "plotly.io.templates.default = 'plotly_white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "img_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../data/torchvision_data_root',\n",
    "                                           train=True,\n",
    "                                           download=True,\n",
    "                                           transform=img_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data/torchvision_data_root',\n",
    "                                          train=False,\n",
    "                                          download=True,\n",
    "                                          transform=img_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=8,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=8*7*7,\n",
    "                      out_features=64),\n",
    "            nn.Linear(in_features=64,\n",
    "                      out_features=16))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=16,\n",
    "                out_features=64),\n",
    "            nn.Linear(\n",
    "                in_features=64,\n",
    "                out_features=8*7*7),\n",
    "            Reshape(-1, 8, 7, 7),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8,\n",
    "                out_channels=8,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8,\n",
    "                out_channels=1,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        print('encoder:', self.encoder)\n",
    "        print('decoder:', self.decoder)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        return self.decoder(h)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.encode(x)\n",
    "        y = self.decode(h)\n",
    "        return y\n",
    "    \n",
    "model = AutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(x):\n",
    "    return x + torch.rand(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_04.pth'\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "except:\n",
    "    n_epochs = 25\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay)\n",
    "\n",
    "    training_history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'test_loss': []}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        for i, train_data in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x, _ = train_data\n",
    "            x_noisy = apply_noise(x)\n",
    "            x = torch.autograd.Variable(x).to(device)\n",
    "            x_noisy = torch.autograd.Variable(x_noisy).to(device)\n",
    "            y = model(x_noisy)\n",
    "            l = criterion(x, y)\n",
    "            train_loss += l.data.item()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= i + 1\n",
    "        if epoch == 0 or (epoch + 1) % 5 == 0:\n",
    "            with torch.no_grad():\n",
    "                test_loss = 0\n",
    "                for i, test_data in enumerate(test_loader, 0):\n",
    "                    x, _ = test_data\n",
    "                    x_noisy = apply_noise(x)\n",
    "                    x = torch.autograd.Variable(x).to(device)\n",
    "                    x_noisy = torch.autograd.Variable(x_noisy).to(device)\n",
    "                    y = model(x_noisy)\n",
    "                    l = criterion(x, y)\n",
    "                    test_loss += l.data.item()\n",
    "                test_loss /= i + 1\n",
    "            training_history['epoch'].append(epoch + 1)\n",
    "            training_history['train_loss'].append(train_loss)\n",
    "            training_history['test_loss'].append(test_loss)\n",
    "            print(f'epoch:{epoch + 1:3d}/{n_epochs:3d}        train loss:{train_loss:10.4f}        test loss:{test_loss:10.4f}')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot(training_history['epoch'],\n",
    "             training_history['train_loss'],\n",
    "             linestyle=':',\n",
    "             c='r',\n",
    "             label='Training loss')\n",
    "    plt.plot(training_history['epoch'],\n",
    "             training_history['test_loss'],\n",
    "             c='r',\n",
    "             label='Test loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim(0, max(training_history['epoch']) + 1)\n",
    "    plt.ylim(0, None)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(test_loader))\n",
    "x_noisy = apply_noise(x)\n",
    "x = torch.autograd.Variable(x).to(device)\n",
    "x_noisy = torch.autograd.Variable(x_noisy).to(device)\n",
    "y = model(x_noisy)\n",
    "\n",
    "x = to_img(x.cpu().data)\n",
    "x_noisy = to_img(x_noisy.cpu().data)\n",
    "y = to_img(y.cpu().data)\n",
    "d = [x, x_noisy, y]\n",
    "\n",
    "plt.figure(figsize=(25, 6))\n",
    "for i in range(3):\n",
    "    for j in range(12):\n",
    "        plt.subplot(3, 12, j + 1 + i*12)\n",
    "        plt.imshow(d[i][j][0], cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction on non-MNIST images from CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(),\n",
    "    torchvision.transforms.CenterCrop(28),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "cifar_dataset = torchvision.datasets.CIFAR10(root='../data/torchvision_data_root',\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=cifar_transform)\n",
    "\n",
    "cifar_loader = torch.utils.data.DataLoader(cifar_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "x, _ = next(iter(cifar_loader))\n",
    "x_noisy = apply_noise(x)\n",
    "x = torch.autograd.Variable(x).to(device)\n",
    "x_noisy = torch.autograd.Variable(x_noisy).to(device)\n",
    "y = model(x_noisy)\n",
    "\n",
    "x = to_img(x.cpu().data)\n",
    "x_noisy = to_img(x_noisy.cpu().data)\n",
    "y = to_img(y.cpu().data)\n",
    "d = [x, x_noisy, y]\n",
    "\n",
    "plt.figure(figsize=(25, 6))\n",
    "for i in range(3):\n",
    "    for j in range(12):\n",
    "        plt.subplot(3, 12, j + 1 + i*12)\n",
    "        plt.imshow(d[i][j][0], cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating output from a random representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for i, test_data in enumerate(test_loader, 0):\n",
    "    x, _ = test_data\n",
    "    x_noisy = apply_noise(x)\n",
    "    x = torch.autograd.Variable(x).to(device)\n",
    "    x_noisy = torch.autograd.Variable(x_noisy).to(device)\n",
    "    h = model.encode(x_noisy)\n",
    "    batches.append(h.detach().cpu().numpy())\n",
    "a = np.concatenate(batches)\n",
    "\n",
    "for i in range(16):\n",
    "    np.random.shuffle(a[:,i])\n",
    "\n",
    "h = torch.from_numpy(a[:64])\n",
    "h = torch.autograd.Variable(h).to(device)\n",
    "\n",
    "y = model.decode(h)\n",
    "y = to_img(y.cpu().data)\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "for i in range(4):\n",
    "    for j in range(12):\n",
    "        plt.subplot(4, 12, j + 1 + i*12)\n",
    "        plt.imshow(y[j + i*12][0], cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
